{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    "    TextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text file\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.join(current_dir, \"Libros\", \"romeo_and_juliet.txt\")\n",
    "db_dir = os.path.join(current_dir, \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the text file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file {file_path} does not exist. Please check the path.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")  # Update to a valid embedding model if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and persist vector store\n",
    "def create_vector_store(docs, store_name):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "        db = Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory\n",
    "        )\n",
    "        print(f\"--- Finished creating vector store {store_name} ---\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Vector store {store_name} already exists. No need to initialize.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1437, which is longer than the specified 1000\n",
      "Created a chunk of size 1871, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1432, which is longer than the specified 1000\n",
      "Created a chunk of size 1367, which is longer than the specified 1000\n",
      "Created a chunk of size 2178, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1502, which is longer than the specified 1000\n",
      "Created a chunk of size 1410, which is longer than the specified 1000\n",
      "Created a chunk of size 1741, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Character-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_char ---\n",
      "--- Finished creating vector store chroma_db_char ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Character-based Splitting\n",
    "# Splits text into chunks based on a specified number of characters.\n",
    "# Useful for consistent chunk sizes regardless of content structure.\n",
    "print(\"\\n--- Using Character-based Splitting ---\")\n",
    "char_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "char_docs = char_splitter.split_documents(documents)\n",
    "create_vector_store(char_docs, \"chroma_db_char\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Sentence-based Splitting ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/g/ubu/miniconda3/envs/Curso_LC/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store chroma_db_sent ---\n",
      "--- Finished creating vector store chroma_db_sent ---\n"
     ]
    }
   ],
   "source": [
    "# 2. Sentence-based Splitting\n",
    "# Splits text into chunks based on sentences, ensuring chunks end at sentence boundaries.\n",
    "# Ideal for maintaining semantic coherence within chunks.\n",
    "print(\"\\n--- Using Sentence-based Splitting ---\")\n",
    "sent_splitter = SentenceTransformersTokenTextSplitter(chunk_size=1000)\n",
    "sent_docs = sent_splitter.split_documents(documents)\n",
    "create_vector_store(sent_docs, \"chroma_db_sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Token-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_token ---\n",
      "--- Finished creating vector store chroma_db_token ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Token-based Splitting\n",
    "# Splits text into chunks based on tokens (words or subwords), using tokenizers like GPT-2.\n",
    "# Useful for transformer models with strict token limits.\n",
    "print(\"\\n--- Using Token-based Splitting ---\")\n",
    "token_splitter = TokenTextSplitter(chunk_overlap=0, chunk_size=512)\n",
    "token_docs = token_splitter.split_documents(documents)\n",
    "create_vector_store(token_docs, \"chroma_db_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Recursive Character-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_rec_char ---\n",
      "--- Finished creating vector store chroma_db_rec_char ---\n"
     ]
    }
   ],
   "source": [
    "# 4. Recursive Character-based Splitting\n",
    "# Attempts to split text at natural boundaries (sentences, paragraphs) within character limit.\n",
    "# Balances between maintaining coherence and adhering to character limits.\n",
    "print(\"\\n--- Using Recursive Character-based Splitting ---\")\n",
    "rec_char_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100)\n",
    "rec_char_docs = rec_char_splitter.split_documents(documents)\n",
    "create_vector_store(rec_char_docs, \"chroma_db_rec_char\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Custom Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_custom ---\n",
      "--- Finished creating vector store chroma_db_custom ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Custom Splitting\n",
    "# Allows creating custom splitting logic based on specific requirements.\n",
    "# Useful for documents with unique structure that standard splitters can't handle.\n",
    "print(\"\\n--- Using Custom Splitting ---\")\n",
    "\n",
    "\n",
    "class CustomTextSplitter(TextSplitter):\n",
    "    def split_text(self, text):\n",
    "        # Custom logic for splitting text\n",
    "        return text.split(\"\\n\\n\")  # Example: split by paragraphs\n",
    "\n",
    "\n",
    "custom_splitter = CustomTextSplitter()\n",
    "custom_docs = custom_splitter.split_documents(documents)\n",
    "create_vector_store(custom_docs, \"chroma_db_custom\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query a vector store\n",
    "def query_vector_store(store_name, query):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Querying the Vector Store {store_name} ---\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory, embedding_function=embeddings\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"k\": 1, \"score_threshold\": 0.1},\n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n--- Relevant Documents for {store_name} ---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"How did Juliet die?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying the Vector Store chroma_db_char ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51367/760185032.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents for chroma_db_char ---\n",
      "Document 1:\n",
      "JULIET.\n",
      "Shall I speak ill of him that is my husband?\n",
      "Ah, poor my lord, what tongue shall smooth thy name,\n",
      "When I thy three-hours’ wife have mangled it?\n",
      "But wherefore, villain, didst thou kill my cousin?\n",
      "That villain cousin would have kill’d my husband.\n",
      "Back, foolish tears, back to your native spring,\n",
      "Your tributary drops belong to woe,\n",
      "Which you mistaking offer up to joy.\n",
      "My husband lives, that Tybalt would have slain,\n",
      "And Tybalt’s dead, that would have slain my husband.\n",
      "All this is comfort; wherefore weep I then?\n",
      "Some word there was, worser than Tybalt’s death,\n",
      "That murder’d me. I would forget it fain,\n",
      "But O, it presses to my memory\n",
      "Like damned guilty deeds to sinners’ minds.\n",
      "Tybalt is dead, and Romeo banished.\n",
      "That ‘banished,’ that one word ‘banished,’\n",
      "Hath slain ten thousand Tybalts. Tybalt’s death\n",
      "Was woe enough, if it had ended there.\n",
      "Or if sour woe delights in fellowship,\n",
      "And needly will be rank’d with other griefs,\n",
      "Why follow’d not, when she said Tybalt’s dead,\n",
      "Thy father or thy mother, nay or both,\n",
      "Which modern lamentation might have mov’d?\n",
      "But with a rear-ward following Tybalt’s death,\n",
      "‘Romeo is banished’—to speak that word\n",
      "Is father, mother, Tybalt, Romeo, Juliet,\n",
      "All slain, all dead. Romeo is banished,\n",
      "There is no end, no limit, measure, bound,\n",
      "In that word’s death, no words can that woe sound.\n",
      "Where is my father and my mother, Nurse?\n",
      "\n",
      "Source: /home/g/Documentos/LangChain_Curso/04_RAGS/Libros/romeo_and_juliet.txt\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_sent ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_sent ---\n",
      "Document 1:\n",
      "am. where is my romeo? [ _ noise within. _ ] friar lawrence. i hear some noise. lady, come from that nest of death, contagion, and unnatural sleep. a greater power than we can contradict hath thwarted our intents. come, come away. thy husband in thy bosom there lies dead ; and paris too. come, i ’ ll dispose of thee among a sisterhood of holy nuns. stay not to question, for the watch is coming. come, go, good juliet. i dare no longer stay. juliet. go, get thee hence, for i will not away. [ _ exit friar lawrence. _ ] what ’ s here? a cup clos ’ d in my true love ’ s hand? poison, i see, hath been his timeless end. o churl. drink all, and left no friendly drop to help me after? i will kiss thy lips. haply some poison yet doth hang on them, to make me die with a restorative. [ _ kisses him. _ ] thy lips are warm! first watch. [ _ within. _ ] lead, boy. which way? juliet. yea, noise? then i ’ ll be brief. o happy dagger. [ _ snatching romeo ’ s dagger. _ ] this is thy sheath. [ _ stabs herself _ ] there rest, and let me die. [ _ falls on romeo ’ s body and dies. _ ] enter watch with the page of paris. page. this is the place. there, where the torch doth burn. first watch. the ground is bloody. search about the churchyard. go, some of you, whoe ’ er you find attach. [ _ exeunt some of the watch. _ ] pitiful sight! here lies the county slain, and juliet bleeding, warm, and newly dead, who\n",
      "\n",
      "Source: /home/g/Documentos/LangChain_Curso/04_RAGS/Libros/romeo_and_juliet.txt\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_token ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_token ---\n",
      "Document 1:\n",
      "The cords that Romeo bid thee fetch?\n",
      "\n",
      "NURSE.\n",
      "Ay, ay, the cords.\n",
      "\n",
      " [_Throws them down._]\n",
      "\n",
      "JULIET.\n",
      "Ay me, what news? Why dost thou wring thy hands?\n",
      "\n",
      "NURSE.\n",
      "Ah, well-a-day, he’s dead, he’s dead, he’s dead!\n",
      "We are undone, lady, we are undone.\n",
      "Alack the day, he’s gone, he’s kill’d, he’s dead.\n",
      "\n",
      "JULIET.\n",
      "Can heaven be so envious?\n",
      "\n",
      "NURSE.\n",
      "Romeo can,\n",
      "Though heaven cannot. O Romeo, Romeo.\n",
      "Who ever would have thought it? Romeo!\n",
      "\n",
      "JULIET.\n",
      "What devil art thou, that dost torment me thus?\n",
      "This torture should be roar’d in dismal hell.\n",
      "Hath Romeo slain himself? Say thou but Ay,\n",
      "And that bare vowel I shall poison more\n",
      "Than the death-darting eye of cockatrice.\n",
      "I am not I if there be such an I;\n",
      "Or those eyes shut that make thee answer Ay.\n",
      "If he be slain, say Ay; or if not, No.\n",
      "Brief sounds determine of my weal or woe.\n",
      "\n",
      "NURSE.\n",
      "I saw the wound, I saw it with mine eyes,\n",
      "God save the mark!—here on his manly breast.\n",
      "A piteous corse, a bloody piteous corse;\n",
      "Pale, pale as ashes, all bedaub’d in blood,\n",
      "All in gore-blood. I swounded at the sight.\n",
      "\n",
      "JULIET.\n",
      "O, break, my heart. Poor bankrout, break at once.\n",
      "To prison, eyes; ne’er look on liberty.\n",
      "Vile earth to earth resign; end motion here,\n",
      "And thou and Romeo press one heavy bier.\n",
      "\n",
      "NURSE.\n",
      "O Tybalt, Tybalt, the best friend I had.\n",
      "O courteous Tybalt, honest gentleman!\n",
      "That ever I should live to see thee dead.\n",
      "\n",
      "JULIET.\n",
      "What storm is this that blows so contrary?\n",
      "Is Romeo slaughter’d and is Tybalt dead?\n",
      "My\n",
      "\n",
      "Source: /home/g/Documentos/LangChain_Curso/04_RAGS/Libros/romeo_and_juliet.txt\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_rec_char ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_rec_char ---\n",
      "Document 1:\n",
      "NURSE.\n",
      "I saw the wound, I saw it with mine eyes,\n",
      "God save the mark!—here on his manly breast.\n",
      "A piteous corse, a bloody piteous corse;\n",
      "Pale, pale as ashes, all bedaub’d in blood,\n",
      "All in gore-blood. I swounded at the sight.\n",
      "\n",
      "JULIET.\n",
      "O, break, my heart. Poor bankrout, break at once.\n",
      "To prison, eyes; ne’er look on liberty.\n",
      "Vile earth to earth resign; end motion here,\n",
      "And thou and Romeo press one heavy bier.\n",
      "\n",
      "NURSE.\n",
      "O Tybalt, Tybalt, the best friend I had.\n",
      "O courteous Tybalt, honest gentleman!\n",
      "That ever I should live to see thee dead.\n",
      "\n",
      "JULIET.\n",
      "What storm is this that blows so contrary?\n",
      "Is Romeo slaughter’d and is Tybalt dead?\n",
      "My dearest cousin, and my dearer lord?\n",
      "Then dreadful trumpet sound the general doom,\n",
      "For who is living, if those two are gone?\n",
      "\n",
      "NURSE.\n",
      "Tybalt is gone, and Romeo banished,\n",
      "Romeo that kill’d him, he is banished.\n",
      "\n",
      "JULIET.\n",
      "O God! Did Romeo’s hand shed Tybalt’s blood?\n",
      "\n",
      "NURSE.\n",
      "It did, it did; alas the day, it did.\n",
      "\n",
      "Source: /home/g/Documentos/LangChain_Curso/04_RAGS/Libros/romeo_and_juliet.txt\n",
      "\n",
      "\n",
      "--- Querying the Vector Store chroma_db_custom ---\n",
      "\n",
      "--- Relevant Documents for chroma_db_custom ---\n",
      "Document 1:\n",
      "JULIET.\n",
      "O God! Did Romeo’s hand shed Tybalt’s blood?\n",
      "\n",
      "Source: /home/g/Documentos/LangChain_Curso/04_RAGS/Libros/romeo_and_juliet.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query each vector store\n",
    "query_vector_store(\"chroma_db_char\", query)\n",
    "query_vector_store(\"chroma_db_sent\", query)\n",
    "query_vector_store(\"chroma_db_token\", query)\n",
    "query_vector_store(\"chroma_db_rec_char\", query)\n",
    "query_vector_store(\"chroma_db_custom\", query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso_LC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
