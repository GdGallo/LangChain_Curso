{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "current_dir = os.getcwd()\n",
    "persistent_directory = os.path.join(\n",
    "    current_dir, \"db\", \"chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7855/1099210415.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=persistent_directory,\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"How can I learn more about LangChain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant documents based on the query\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "“The leader of the gang. I shall have the others, but he first.”\n",
      "\n",
      "“How did you trace it, then?”\n",
      "\n",
      "He took a large sheet of paper from his pocket, all covered with dates\n",
      "and names.\n",
      "\n",
      "“I have spent the whole day,” said he, “over Lloyd’s registers and\n",
      "files of the old papers, following the future career of every vessel\n",
      "which touched at Pondicherry in January and February in ’83. There were\n",
      "thirty-six ships of fair tonnage which were reported there during those\n",
      "months. Of these, one, the _Lone Star_, instantly attracted my\n",
      "attention, since, although it was reported as having cleared from\n",
      "London, the name is that which is given to one of the states of the\n",
      "Union.”\n",
      "\n",
      "“Texas, I think.”\n",
      "\n",
      "“I was not and am not sure which; but I knew that the ship must have an\n",
      "American origin.”\n",
      "\n",
      "“What then?”\n",
      "\n",
      "Document 2:\n",
      "Section 3. Information about the Project Gutenberg Literary Archive Foundation\n",
      "\n",
      "The Project Gutenberg Literary Archive Foundation is a non-profit\n",
      "501(c)(3) educational corporation organized under the laws of the\n",
      "state of Mississippi and granted tax exempt status by the Internal\n",
      "Revenue Service. The Foundation’s EIN or federal tax identification\n",
      "number is 64-6221541. Contributions to the Project Gutenberg Literary\n",
      "Archive Foundation are tax deductible to the full extent permitted by\n",
      "U.S. federal laws and your state’s laws.\n",
      "\n",
      "The Foundation’s business office is located at 809 North 1500 West,\n",
      "Salt Lake City, UT 84116, (801) 596-1887. Email contact links and up\n",
      "to date contact information can be found at the Foundation’s website\n",
      "and official page at www.gutenberg.org/contact\n",
      "\n",
      "Section 4. Information about Donations to the Project Gutenberg\n",
      "Literary Archive Foundation\n",
      "\n",
      "Document 3:\n",
      "DR. LANYON’S NARRATIVE\n",
      "\n",
      "On the ninth of January, now four days ago, I received by the evening\n",
      "delivery a registered envelope, addressed in the hand of my colleague\n",
      "and old school companion, Henry Jekyll. I was a good deal surprised by\n",
      "this; for we were by no means in the habit of correspondence; I had\n",
      "seen the man, dined with him, indeed, the night before; and I could\n",
      "imagine nothing in our intercourse that should justify formality of\n",
      "registration. The contents increased my wonder; for this is how the\n",
      "letter ran:\n",
      "\n",
      "“10_th December_, 18—.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the query and the relevant document contents\n",
    "combined_input = (\n",
    "    \"Here are some documents that might help answer the question: \"\n",
    "    + query\n",
    "    + \"\\n\\nRelevant Documents:\\n\"\n",
    "    + \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    + \"\\n\\nPlease provide an answer based only on the provided documents. If the answer is not found in the documents, respond with 'I'm not sure'.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define the messages for the model\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=combined_input),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model with the combined input\n",
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Response ---\n",
      "Content only:\n",
      "I'm not sure.\n"
     ]
    }
   ],
   "source": [
    "# Display the full result and content only\n",
    "print(\"\\n--- Generated Response ---\")\n",
    "# print(\"Full result:\")\n",
    "# print(result)\n",
    "print(\"Content only:\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso_LC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
